# ü§ñ Taller Sesi√≥n 4: Chatbot con LangChain y Gesti√≥n de Contexto

**Curso:** Dise√±o e Implementaci√≥n de Chatbots
**Docente:** Angelo Castillo Meca

---

## üìã Descripci√≥n

Este taller te ense√±a a implementar un asistente conversacional para e-commerce usando LangChain, con gesti√≥n de memoria conversacional y orquestaci√≥n de LLMs.

## üéØ Objetivos de Aprendizaje

- Usar LangChain para orquestar interacciones con LLMs
- Implementar gesti√≥n de memoria conversacional
- Dise√±ar prompts efectivos para chatbots especializados
- Crear cadenas de procesamiento (Chains)
- Construir un chatbot con contexto persistente

## üì¶ Requisitos

### API Key de OpenAI

**‚ö†Ô∏è IMPORTANTE:** Este taller requiere una API key de OpenAI.

1. Crea una cuenta en [OpenAI](https://platform.openai.com/)
2. Ve a [API Keys](https://platform.openai.com/api-keys)
3. Crea una nueva API key
4. **Nota:** Nuevas cuentas tienen $5 de cr√©dito gratis

**Alternativa Gratuita:** El notebook incluye una secci√≥n para usar modelos locales de HuggingFace (sin costo)

### Python y Dependencias

```bash
pip install langchain langchain-community langchain-openai openai python-dotenv
```

### Versiones Recomendadas

- Python 3.8 o superior
- langchain >= 0.1.0
- openai >= 1.0.0

## üöÄ C√≥mo Usar el Taller

### Opci√≥n 1: Google Colab (Recomendado)

1. Abre el notebook en Google Colab:
   - Ve a [Google Colab](https://colab.research.google.com/)
   - Selecciona "Archivo" ‚Üí "Abrir cuaderno"
   - Sube el archivo `Taller_Sesion4_LangChain_Chatbot.ipynb`

2. **Configura tu API Key:**
   ```python
   # El notebook te pedir√° la API key de forma segura
   # NO la compartas ni la subas a repositorios p√∫blicos
   ```

3. Ejecuta las celdas en orden

### Opci√≥n 2: Jupyter Notebook Local

1. Instala Jupyter:
   ```bash
   pip install jupyter
   ```

2. **Configura tu API Key (Opci√≥n A - Variable de entorno):**
   ```bash
   # Linux/Mac
   export OPENAI_API_KEY='tu-api-key-aqu√≠'

   # Windows (CMD)
   set OPENAI_API_KEY=tu-api-key-aqu√≠

   # Windows (PowerShell)
   $env:OPENAI_API_KEY='tu-api-key-aqu√≠'
   ```

3. **Configura tu API Key (Opci√≥n B - Archivo .env):**
   ```bash
   # Crea archivo .env en la misma carpeta del notebook
   echo "OPENAI_API_KEY=tu-api-key-aqu√≠" > .env
   ```

4. Inicia Jupyter:
   ```bash
   jupyter notebook
   ```

5. Abre el archivo `Taller_Sesion4_LangChain_Chatbot.ipynb`

### Opci√≥n 3: VS Code

1. Instala extensiones: "Jupyter" y "Python"
2. Abre el archivo `.ipynb`
3. Configura la API key (mismo proceso que Jupyter Local)
4. Ejecuta las celdas

## üìö Contenido del Taller

### Parte 1-3: Setup Inicial
- Instalaci√≥n de dependencias
- Configuraci√≥n de API key
- Importar bibliotecas

### Parte 4: Inicializar LLM
- Configuraci√≥n de ChatOpenAI
- Par√°metros: temperature, max_tokens

### Parte 5: Memoria Conversacional
- ConversationBufferMemory (completo)
- ConversationBufferWindowMemory (ventana)
- ConversationSummaryMemory (resumen)

### Parte 6: Prompt Engineering
- Dise√±o de prompt template
- Contexto de e-commerce
- Cat√°logo de productos
- Pol√≠ticas de la tienda

### Parte 7: ConversationChain
- Integraci√≥n LLM + Memoria + Prompt
- Cadena de procesamiento completa

### Parte 8-10: Chatbot Funcional
- Clase `ChatbotEcommerce`
- M√©todos: chat, reset, ver_historial
- Conversaci√≥n de ejemplo
- Estad√≠sticas

### Parte 11: Tipos de Memoria
- Comparaci√≥n de estrategias
- Pruebas con ventana limitada

### Parte 12: Chat Interactivo
- Loop en consola
- Comandos especiales

### Parte 13: Ejercicios Propuestos
- Sistema de descuentos
- Filtrado inteligente
- Integraci√≥n con DB
- Sentiment analysis

### Alternativa: Modelos Locales
- Uso de HuggingFace sin API key
- Configuraci√≥n alternativa

## üîë Gesti√≥n Segura de API Keys

### ‚úÖ Hacer:
- Usar variables de entorno
- Usar archivos `.env` (y agregarlos a `.gitignore`)
- Usar servicios de secrets management en producci√≥n
- Rotar keys peri√≥dicamente

### ‚ùå NO Hacer:
- Hardcodear la API key en el c√≥digo
- Subir la API key a GitHub/GitLab
- Compartir la API key en capturas de pantalla
- Usar la misma key en m√∫ltiples proyectos

### Ejemplo Seguro:

```python
import os
from dotenv import load_dotenv

# Cargar desde archivo .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# O solicitar al usuario (como en el notebook)
import getpass
api_key = getpass.getpass("Ingresa tu API Key: ")
```

## ‚öôÔ∏è Configuraci√≥n del LLM

### Modelos Disponibles (OpenAI)

1. **gpt-3.5-turbo** (Usado en el taller)
   - Costo: $0.0005 / 1K tokens (input)
   - Velocidad: R√°pida
   - Calidad: Alta
   - Recomendado para: Producci√≥n

2. **gpt-4**
   - Costo: $0.03 / 1K tokens (input)
   - Velocidad: Media
   - Calidad: Muy alta
   - Recomendado para: Tareas complejas

3. **gpt-4-turbo**
   - Costo: $0.01 / 1K tokens (input)
   - Velocidad: R√°pida
   - Calidad: Muy alta
   - Recomendado para: Balance costo/calidad

### Par√°metros del LLM

```python
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.7,      # Creatividad (0.0-2.0)
    max_tokens=500,       # Longitud de respuesta
    model_kwargs={
        "top_p": 0.9,     # Nucleus sampling
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }
)
```

### Temperature:
- **0.0-0.3:** Determin√≠stico, preciso (FAQs, soporte)
- **0.7-0.9:** Balanceado (conversaci√≥n general)
- **1.0-2.0:** Creativo (brainstorming, storytelling)

## üíæ Tipos de Memoria en LangChain

### 1. ConversationBufferMemory
- **Uso:** Almacena todo el historial
- **Ventaja:** Contexto completo
- **Desventaja:** Puede exceder l√≠mite de tokens
- **Recomendado para:** Conversaciones cortas/medias

### 2. ConversationBufferWindowMemory
- **Uso:** Solo √∫ltimas K interacciones
- **Ventaja:** Control de tama√±o
- **Desventaja:** Pierde contexto antiguo
- **Recomendado para:** Conversaciones largas

```python
memory = ConversationBufferWindowMemory(k=5)  # √öltimas 5 interacciones
```

### 3. ConversationSummaryMemory
- **Uso:** Resume autom√°ticamente el historial
- **Ventaja:** Mantiene esencia con menos tokens
- **Desventaja:** Costo adicional (resumen usa LLM)
- **Recomendado para:** Conversaciones muy largas

```python
memory = ConversationSummaryMemory(llm=llm)
```

## üí° Tips y Mejores Pr√°cticas

### Prompt Engineering

1. **Define el rol claramente:**
   ```
   "Eres un asistente virtual experto en [dominio]"
   ```

2. **Proporciona contexto:**
   - Cat√°logo de productos
   - Pol√≠ticas de la empresa
   - Limitaciones del asistente

3. **Especifica el formato:**
   - Tono (formal/informal)
   - Longitud de respuestas
   - Estructura (bullets, p√°rrafos)

4. **Incluye instrucciones de seguridad:**
   - "Si no tienes informaci√≥n, adm√≠telo"
   - "No inventes datos"
   - "Cita las fuentes cuando sea relevante"

### Optimizaci√≥n de Costos

1. **Usa el modelo apropiado:**
   - gpt-3.5-turbo para la mayor√≠a de casos
   - gpt-4 solo cuando sea necesario

2. **Limita el contexto:**
   - Usa ConversationBufferWindowMemory
   - No env√≠es informaci√≥n redundante

3. **Cachea respuestas frecuentes:**
   - FAQ com√∫n ‚Üí respuesta pre-generada
   - Solo usa LLM para consultas √∫nicas

4. **Monitorea el uso:**
   ```python
   # Ver cu√°ntos tokens consume
   from langchain.callbacks import get_openai_callback

   with get_openai_callback() as cb:
       response = conversation.predict(input=mensaje)
       print(f"Tokens: {cb.total_tokens}, Costo: ${cb.total_cost}")
   ```

## üêõ Troubleshooting

### Error: "Invalid API Key"
**Soluci√≥n:**
- Verifica que la API key sea correcta
- Revisa que no tenga espacios al inicio/final
- Confirma que la cuenta tenga cr√©dito disponible

### Error: "Rate limit exceeded"
**Soluci√≥n:**
- Has excedido el l√≠mite de requests por minuto
- Espera 60 segundos
- Considera upgrade de cuenta

### Error: "Context length exceeded"
**Soluci√≥n:**
- Reduce `max_tokens`
- Usa ConversationBufferWindowMemory con k m√°s peque√±o
- Limpia la memoria: `conversation.memory.clear()`

### Respuestas en ingl√©s
**Soluci√≥n:**
- Agrega al prompt: "IMPORTANTE: Responde SIEMPRE en espa√±ol"
- Verifica que los ejemplos en el prompt est√©n en espa√±ol

## üí∞ Estimaci√≥n de Costos

### Ejemplo de Conversaci√≥n:

- **Modelo:** gpt-3.5-turbo
- **Conversaci√≥n:** 10 turnos
- **Promedio por turno:** 500 tokens (input + output)
- **Total:** ~5,000 tokens
- **Costo:** ~$0.0025 (menos de 1 centavo)

### Costo por 1000 conversaciones:
- **gpt-3.5-turbo:** ~$2.50
- **gpt-4:** ~$150

**Conclusi√≥n:** Para producci√≥n, gpt-3.5-turbo es muy econ√≥mico.

## üìä Tiempo Estimado

- Setup inicial (incluye API key): 15-20 minutos
- Completar taller: 75-90 minutos
- Ejercicios adicionales: 45-60 minutos

## üéì Ejercicios Propuestos

### Ejercicio 1: Sistema de Descuentos (30 min)
Implementa l√≥gica para aplicar descuentos autom√°ticos

### Ejercicio 2: Filtrado Inteligente (20 min)
Filtra productos por rango de precios y caracter√≠sticas

### Ejercicio 3: Integraci√≥n con SQLite (45 min)
Conecta a una base de datos real para productos din√°micos

### Ejercicio 4: Sentiment Analysis (30 min)
Detecta clientes insatisfechos y escala a humano

### Ejercicio 5: Multi-idioma (25 min)
Agrega soporte para ingl√©s/espa√±ol autom√°tico

## üìö Recursos Adicionales

- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [LangChain Memory Guide](https://python.langchain.com/docs/modules/memory/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

## üÜì Alternativa Sin Costo

El notebook incluye c√≥digo (comentado) para usar modelos locales de HuggingFace:

```python
# Usar google/flan-t5-base local (sin API key)
from langchain_huggingface import HuggingFacePipeline

llm_local = HuggingFacePipeline.from_model_id(
    model_id="google/flan-t5-base",
    task="text2text-generation"
)
```

**Ventajas:**
- Sin costo
- Sin l√≠mites de uso
- Privacidad total

**Desventajas:**
- Menor calidad que GPT-3.5/4
- Requiere m√°s memoria RAM
- M√°s lento

## üÜò Soporte

Si tienes problemas:
1. Revisa la secci√≥n de Troubleshooting
2. Consulta la documentaci√≥n de LangChain
3. Contacta al docente: castillomeca53@gmail.com

---

**¬°√âxito en tu taller!** üöÄ
