{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Taller SesiÃ³n 4: Chatbot con LangChain y GestiÃ³n de Contexto\n",
    "\n",
    "**Curso:** DiseÃ±o e ImplementaciÃ³n de Chatbots  \n",
    "**Docente:** Angelo Castillo Meca  \n",
    "**SesiÃ³n:** 4 - Chatbot basado en LLMs\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Objetivo del Taller\n",
    "\n",
    "Implementar un **asistente conversacional para e-commerce** usando LangChain que pueda:\n",
    "- Responder preguntas sobre productos\n",
    "- Procesar consultas de seguimiento\n",
    "- Generar recomendaciones personalizadas\n",
    "- Mantener contexto conversacional\n",
    "\n",
    "## ğŸ¯ Competencias a Desarrollar\n",
    "\n",
    "1. Usar LangChain para orquestar interacciones con LLMs\n",
    "2. Implementar gestiÃ³n de memoria conversacional\n",
    "3. DiseÃ±ar prompts efectivos para chatbots\n",
    "4. Crear cadenas de procesamiento (Chains)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Parte 1: InstalaciÃ³n de Dependencias\n",
    "\n",
    "Instalamos LangChain y las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "print(\"âœ… Dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”‘ Parte 2: ConfiguraciÃ³n de API Key\n",
    "\n",
    "**Importante:** Necesitas una API key de OpenAI. Puedes obtenerla en: https://platform.openai.com/api-keys\n",
    "\n",
    "**Alternativa Gratuita:** Si no tienes API key, puedes usar modelos locales con HuggingFace (ver secciÃ³n alternativa al final)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Key de Alibaba DashScope configurada\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Configurar API key de Alibaba DashScope\n",
    "if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Ingresa tu DashScope API Key: \")\n",
    "# sk-0f8e7079049345b7bed6fc8d494b995e\n",
    "# LangChain usa OPENAI_API_KEY, asÃ­ que la asignamos tambiÃ©n\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"DASHSCOPE_API_KEY\"]\n",
    "    \n",
    "print(\"âœ… API Key de Alibaba DashScope configurada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Parte 3: Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bibliotecas importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_classic.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    ConversationEntityMemory\n",
    ")\n",
    "from langchain_classic.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_classic.schema import HumanMessage, AIMessage, SystemMessage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Parte 4: Inicializar el Modelo LLM\n",
    "\n",
    "Configuramos el modelo de OpenAI con parÃ¡metros apropiados para un chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo LLM inicializado con Alibaba DashScope\n",
      "   Modelo: qwen-turbo\n",
      "   Base URL: https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n",
      "   Temperature: 0.7\n",
      "   Max tokens: 500\n",
      "\n",
      "ğŸ’¡ Modelos disponibles de Alibaba:\n",
      "   - qwen-turbo (rÃ¡pido y econÃ³mico)\n",
      "   - qwen-plus (equilibrado)\n",
      "   - qwen-max (mÃ¡s potente)\n",
      "   - qwen-max-longcontext (contexto largo)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar modelo LLM usando Alibaba DashScope\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",  # Modelos disponibles: qwen-turbo, qwen-plus, qwen-max, qwen-max-longcontext\n",
    "    temperature=0.7,     # Control de creatividad (0.0 = conservador, 1.0 = creativo)\n",
    "    max_tokens=500,      # MÃ¡ximo de tokens en la respuesta\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"  # URL de Alibaba DashScope\n",
    ")\n",
    "\n",
    "print(\"âœ… Modelo LLM inicializado con Alibaba DashScope\")\n",
    "print(f\"   Modelo: qwen-turbo\")\n",
    "print(f\"   Base URL: https://dashscope-intl.aliyuncs.com/compatible-mode/v1\")\n",
    "print(f\"   Temperature: 0.7\")\n",
    "print(f\"   Max tokens: 500\")\n",
    "print(\"\\nğŸ’¡ Modelos disponibles de Alibaba:\")\n",
    "print(\"   - qwen-turbo (rÃ¡pido y econÃ³mico)\")\n",
    "print(\"   - qwen-plus (equilibrado)\")\n",
    "print(\"   - qwen-max (mÃ¡s potente)\")\n",
    "print(\"   - qwen-max-longcontext (contexto largo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’­ Parte 5: Configurar Memoria Conversacional\n",
    "\n",
    "La memoria permite que el chatbot recuerde interacciones previas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memoria conversacional configurada\n",
      "   Tipo: ConversationBufferMemory (almacena todo el historial)\n"
     ]
    }
   ],
   "source": [
    "# Crear memoria conversacional (buffer completo)\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,  # Retornar como lista de mensajes\n",
    "    memory_key=\"chat_history\"  # Nombre de la variable en el prompt\n",
    ")\n",
    "\n",
    "print(\"âœ… Memoria conversacional configurada\")\n",
    "print(\"   Tipo: ConversationBufferMemory (almacena todo el historial)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Parte 6: DiseÃ±ar Prompt Template\n",
    "\n",
    "El prompt define el rol y comportamiento del chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt template creado\n"
     ]
    }
   ],
   "source": [
    "# Template del prompt para el asistente de e-commerce\n",
    "template = \"\"\"Eres un asistente virtual amigable y experto para una tienda de tecnologÃ­a online llamada \"TechStore\". \n",
    "\n",
    "Tu objetivo es ayudar a los clientes a:\n",
    "- Encontrar productos que se ajusten a sus necesidades\n",
    "- Responder preguntas sobre especificaciones y caracterÃ­sticas\n",
    "- Hacer recomendaciones personalizadas\n",
    "- Resolver dudas sobre envÃ­os, garantÃ­as y devoluciones\n",
    "\n",
    "CatÃ¡logo de productos disponibles:\n",
    "1. Laptop HP Pavilion 15 - $899 - Intel i5, 8GB RAM, 256GB SSD, Pantalla 15.6\"\n",
    "2. Mouse Logitech MX Master 3 - $99 - InalÃ¡mbrico, ErgonÃ³mico, 7 botones programables\n",
    "3. Teclado MecÃ¡nico Keychron K2 - $79 - Bluetooth, RGB, Switch Brown\n",
    "4. Monitor Dell 27\" 4K - $449 - IPS, HDR, 60Hz, USB-C\n",
    "5. Webcam Logitech C920 - $79 - Full HD 1080p, MicrÃ³fono integrado\n",
    "6. Auriculares Sony WH-1000XM5 - $399 - CancelaciÃ³n de ruido, Bluetooth, 30h baterÃ­a\n",
    "\n",
    "PolÃ­ticas de la tienda:\n",
    "- EnvÃ­o gratis en compras mayores a $100\n",
    "- Devoluciones: 30 dÃ­as desde la compra\n",
    "- GarantÃ­a: 1 aÃ±o en todos los productos\n",
    "- MÃ©todos de pago: Tarjetas de crÃ©dito/dÃ©bito, PayPal\n",
    "\n",
    "Responde de manera:\n",
    "- Clara y concisa\n",
    "- Amigable y profesional\n",
    "- Basada en el catÃ¡logo proporcionado\n",
    "- Si no tienes informaciÃ³n, admÃ­telo honestamente\n",
    "\n",
    "Historial de conversaciÃ³n:\n",
    "{chat_history}\n",
    "\n",
    "Cliente: {input}\n",
    "Asistente:\"\"\"\n",
    "\n",
    "# Crear el prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "print(\"âœ… Prompt template creado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Parte 7: Crear la Cadena de ConversaciÃ³n\n",
    "\n",
    "Integramos LLM + Memoria + Prompt en una ConversationChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cadena de conversaciÃ³n creada\n",
      "   Componentes: LLM + Memoria + Prompt\n"
     ]
    }
   ],
   "source": [
    "# Crear la cadena de conversaciÃ³n\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=False  # Cambiar a True para ver el proceso interno\n",
    ")\n",
    "\n",
    "print(\"âœ… Cadena de conversaciÃ³n creada\")\n",
    "print(\"   Componentes: LLM + Memoria + Prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¬ Parte 8: Chatbot Interactivo - Clase Wrapper\n",
    "\n",
    "Creamos una clase para manejar el chatbot de manera mÃ¡s elegante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chatbot de E-commerce listo para usar\n",
      "\n",
      "ğŸ’¡ Comandos disponibles:\n",
      "   - chatbot.chat('tu mensaje'): Enviar mensaje\n",
      "   - chatbot.ver_historial(): Ver conversaciÃ³n completa\n",
      "   - chatbot.reset(): Reiniciar conversaciÃ³n\n",
      "   - chatbot.estadisticas(): Ver estadÃ­sticas\n"
     ]
    }
   ],
   "source": [
    "class ChatbotEcommerce:\n",
    "    \"\"\"\n",
    "    Chatbot para e-commerce con LangChain\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conversation_chain):\n",
    "        self.conversation = conversation_chain\n",
    "        self.num_interacciones = 0\n",
    "    \n",
    "    def chat(self, mensaje_usuario):\n",
    "        \"\"\"\n",
    "        EnvÃ­a un mensaje al chatbot y obtiene respuesta\n",
    "        \n",
    "        Args:\n",
    "            mensaje_usuario (str): Mensaje del usuario\n",
    "            \n",
    "        Returns:\n",
    "            str: Respuesta del chatbot\n",
    "        \"\"\"\n",
    "        self.num_interacciones += 1\n",
    "        \n",
    "        try:\n",
    "            respuesta = self.conversation.predict(input=mensaje_usuario)\n",
    "            return respuesta\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reinicia la memoria del chatbot\"\"\"\n",
    "        self.conversation.memory.clear()\n",
    "        self.num_interacciones = 0\n",
    "        print(\"ğŸ”„ Memoria reiniciada\")\n",
    "    \n",
    "    def ver_historial(self):\n",
    "        \"\"\"Muestra el historial de conversaciÃ³n\"\"\"\n",
    "        historial = self.conversation.memory.load_memory_variables({})\n",
    "        print(\"\\nğŸ“œ Historial de ConversaciÃ³n:\")\n",
    "        print(\"=\" * 80)\n",
    "        if 'chat_history' in historial:\n",
    "            for msg in historial['chat_history']:\n",
    "                msg_str = \"\"\n",
    "                for ind in range(0, len(msg.content), 80):\n",
    "                    msg_str += msg.content[ind:ind+80]+\"\\n\"\n",
    "                if isinstance(msg, HumanMessage):\n",
    "                    print(f\"ğŸ‘¤ Usuario: {msg_str}\")\n",
    "                elif isinstance(msg, AIMessage):\n",
    "                    print(f\"ğŸ¤– Asistente: {msg_str}\")\n",
    "                    print(\"-\" * 80)\n",
    "        print(f\"\\nTotal de interacciones: {self.num_interacciones}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    def estadisticas(self):\n",
    "        \"\"\"Muestra estadÃ­sticas de la conversaciÃ³n\"\"\"\n",
    "        historial = self.conversation.memory.load_memory_variables({})\n",
    "        num_mensajes = len(historial.get('chat_history', []))\n",
    "        \n",
    "        print(\"\\nğŸ“Š EstadÃ­sticas:\")\n",
    "        print(f\"   Total de mensajes en memoria: {num_mensajes}\")\n",
    "        print(f\"   Interacciones del usuario: {self.num_interacciones}\")\n",
    "\n",
    "# Crear instancia del chatbot\n",
    "chatbot = ChatbotEcommerce(conversation)\n",
    "\n",
    "print(\"âœ… Chatbot de E-commerce listo para usar\")\n",
    "print(\"\\nğŸ’¡ Comandos disponibles:\")\n",
    "print(\"   - chatbot.chat('tu mensaje'): Enviar mensaje\")\n",
    "print(\"   - chatbot.ver_historial(): Ver conversaciÃ³n completa\")\n",
    "print(\"   - chatbot.reset(): Reiniciar conversaciÃ³n\")\n",
    "print(\"   - chatbot.estadisticas(): Ver estadÃ­sticas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Parte 9: Probar el Chatbot\n",
    "\n",
    "Simulemos una conversaciÃ³n real con el chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– CHATBOT DE E-COMMERCE - TECHSTORE\n",
      "================================================================================\n",
      "\n",
      "ğŸ‘¤ USER: Hola, estoy buscando una laptop para trabajar desde casa\n",
      "ğŸ¤– ASSISTANT: Â¡Hola! Â¡Bienvenido a TechStore! Claro, estarÃ© encantado de ayudarte a encontrar la laptop ideal para trabajar desde casa. Â¿PodrÃ­as decirme un poco mÃ¡s sobre tus necesidades? Por ejemplo:\n",
      "\n",
      "- Â¿QuÃ© tipo de trabajo realizas (oficina, diseÃ±o grÃ¡fico, programaciÃ³n, etc.)?\n",
      "- Â¿Necesitas una baterÃ­a duradera?\n",
      "- Â¿Tienes un presupuesto especÃ­fico?\n",
      "\n",
      "Esto me ayudarÃ¡ a recomendarte la mejor opciÃ³n. ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ‘¤ USER: Â¿CuÃ¡nto cuesta?\n",
      "ğŸ¤– ASSISTANT: La laptop HP Pavilion 15 cuesta $899. Es una excelente opciÃ³n para trabajar desde casa, ya que cuenta con un procesador Intel i5, 8GB de RAM y 256GB de SSD, lo que ofrece un buen equilibrio entre rendimiento y almacenamiento. Â¿Te gustarÃ­a que te ayude a elegir entre otras opciones disponibles? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ‘¤ USER: Â¿Tiene envÃ­o gratis?\n",
      "ğŸ¤– ASSISTANT: Â¡SÃ­, tenemos envÃ­o gratis en todas las compras mayores a $100! ğŸ˜Š Si tu compra alcanza ese monto, podrÃ¡s disfrutar del envÃ­o gratuito. Â¿Te gustarÃ­a que te ayude a ver quÃ© combinaciÃ³n de productos podrÃ­a alcanzar ese monto?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ‘¤ USER: Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\n",
      "ğŸ¤– ASSISTANT: Â¡Claro que sÃ­! Tenemos el **Mouse Logitech MX Master 3** que podrÃ­a ser una excelente opciÃ³n para ti. Cuesta $99 y es inalÃ¡mbrico, ergonÃ³mico y tiene 7 botones programables, lo cual es ideal para trabajar de manera cÃ³moda y eficiente.  \n",
      "\n",
      "Â¿Te gustarÃ­a que te lo incluyera en una combinaciÃ³n con la laptop HP Pavilion 15 para ver si alcanzamos el monto del envÃ­o gratis? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ‘¤ USER: Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\n",
      "ğŸ¤– ASSISTANT: Â¡Perfecto! Si te interesa la laptop HP Pavilion 15 ($899) y el Mouse Logitech MX Master 3 ($99), el total serÃ­a de **$998**.  \n",
      "\n",
      "EstÃ¡s muy cerca del monto para obtener envÃ­o gratis (que empieza en $100). Â¿Te gustarÃ­a que te ayude a agregar un producto adicional para alcanzar el envÃ­o gratuito? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¤– CHATBOT DE E-COMMERCE - TECHSTORE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ConversaciÃ³n de ejemplo\n",
    "mensajes = [\n",
    "    \"Hola, estoy buscando una laptop para trabajar desde casa\",\n",
    "    \"Â¿CuÃ¡nto cuesta?\",\n",
    "    \"Â¿Tiene envÃ­o gratis?\",\n",
    "    \"Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\",\n",
    "    \"Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\"\n",
    "]\n",
    "\n",
    "for mensaje in mensajes:\n",
    "    print(f\"\\nğŸ‘¤ USER: {mensaje}\")\n",
    "    respuesta = chatbot.chat(mensaje)\n",
    "    print(f\"ğŸ¤– ASSISTANT: {respuesta}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“œ Historial de ConversaciÃ³n:\n",
      "================================================================================\n",
      "ğŸ‘¤ Usuario: Hola, estoy buscando una laptop para trabajar desde casa\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Hola! Â¡Bienvenido a TechStore! Claro, estarÃ© encantado de ayudarte a encontrar \n",
      "la laptop ideal para trabajar desde casa. Â¿PodrÃ­as decirme un poco mÃ¡s sobre tus\n",
      " necesidades? Por ejemplo:\n",
      "\n",
      "- Â¿QuÃ© tipo de trabajo realizas (oficina, diseÃ±o grÃ¡\n",
      "fico, programaciÃ³n, etc.)?\n",
      "- Â¿Necesitas una baterÃ­a duradera?\n",
      "- Â¿Tienes un presu\n",
      "puesto especÃ­fico?\n",
      "\n",
      "Esto me ayudarÃ¡ a recomendarte la mejor opciÃ³n. ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿CuÃ¡nto cuesta?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: La laptop HP Pavilion 15 cuesta $899. Es una excelente opciÃ³n para trabajar desd\n",
      "e casa, ya que cuenta con un procesador Intel i5, 8GB de RAM y 256GB de SSD, lo \n",
      "que ofrece un buen equilibrio entre rendimiento y almacenamiento. Â¿Te gustarÃ­a q\n",
      "ue te ayude a elegir entre otras opciones disponibles? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿Tiene envÃ­o gratis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡SÃ­, tenemos envÃ­o gratis en todas las compras mayores a $100! ğŸ˜Š Si tu compra al\n",
      "canza ese monto, podrÃ¡s disfrutar del envÃ­o gratuito. Â¿Te gustarÃ­a que te ayude \n",
      "a ver quÃ© combinaciÃ³n de productos podrÃ­a alcanzar ese monto?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Claro que sÃ­! Tenemos el **Mouse Logitech MX Master 3** que podrÃ­a ser una exce\n",
      "lente opciÃ³n para ti. Cuesta $99 y es inalÃ¡mbrico, ergonÃ³mico y tiene 7 botones \n",
      "programables, lo cual es ideal para trabajar de manera cÃ³moda y eficiente. \n",
      "\n",
      "Â¿Te\n",
      " gustarÃ­a que te lo incluyera en una combinaciÃ³n con la laptop HP Pavilion 15 pa\n",
      "ra ver si alcanzamos el monto del envÃ­o gratis? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Perfecto! Si te interesa la laptop HP Pavilion 15 ($899) y el Mouse Logitech MX\n",
      " Master 3 ($99), el total serÃ­a de **$998**. \n",
      "\n",
      "EstÃ¡s muy cerca del monto para ob\n",
      "tener envÃ­o gratis (que empieza en $100). Â¿Te gustarÃ­a que te ayude a agregar un\n",
      " producto adicional para alcanzar el envÃ­o gratuito? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Hola, estoy buscando una laptop para trabajar desde casa\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Hola! Â¡Bienvenido a TechStore! Claro, estarÃ© encantado de ayudarte a encontrar \n",
      "la laptop ideal para trabajar desde casa. Â¿PodrÃ­as decirme un poco mÃ¡s sobre tus\n",
      " necesidades? Por ejemplo:\n",
      "\n",
      "- Â¿QuÃ© tipo de trabajo realizas (oficina, diseÃ±o grÃ¡\n",
      "fico, programaciÃ³n, etc.)?\n",
      "- Â¿Necesitas una baterÃ­a duradera?\n",
      "- Â¿Tienes un presu\n",
      "puesto especÃ­fico?\n",
      "\n",
      "Esto me ayudarÃ¡ a recomendarte la mejor opciÃ³n. ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿CuÃ¡nto cuesta?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: La laptop HP Pavilion 15 cuesta $899. Es una excelente opciÃ³n para trabajar desd\n",
      "e casa, ya que cuenta con un procesador Intel i5, 8GB de RAM y 256GB de SSD, lo \n",
      "que ofrece un buen equilibrio entre rendimiento y almacenamiento. Â¿Te gustarÃ­a q\n",
      "ue te ayude a elegir entre otras opciones disponibles? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿Tiene envÃ­o gratis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡SÃ­, tenemos envÃ­o gratis en todas las compras mayores a $100! ğŸ˜Š Si tu compra al\n",
      "canza ese monto, podrÃ¡s disfrutar del envÃ­o gratuito. Â¿Te gustarÃ­a que te ayude \n",
      "a ver quÃ© combinaciÃ³n de productos podrÃ­a alcanzar ese monto?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Claro que sÃ­! Tenemos el **Mouse Logitech MX Master 3** que podrÃ­a ser una exce\n",
      "lente opciÃ³n para ti. Cuesta $99 y es inalÃ¡mbrico, ergonÃ³mico y tiene 7 botones \n",
      "programables, lo cual es ideal para trabajar de manera cÃ³moda y eficiente.  \n",
      "\n",
      "Â¿T\n",
      "e gustarÃ­a que te lo incluyera en una combinaciÃ³n con la laptop HP Pavilion 15 p\n",
      "ara ver si alcanzamos el monto del envÃ­o gratis? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Asistente: Â¡Perfecto! Si te interesa la laptop HP Pavilion 15 ($899) y el Mouse Logitech MX\n",
      " Master 3 ($99), el total serÃ­a de **$998**.  \n",
      "\n",
      "EstÃ¡s muy cerca del monto para o\n",
      "btener envÃ­o gratis (que empieza en $100). Â¿Te gustarÃ­a que te ayude a agregar u\n",
      "n producto adicional para alcanzar el envÃ­o gratuito? ğŸ˜Š\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de interacciones: 5\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "chatbot.ver_historial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Parte 10: Ver Historial y EstadÃ­sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“œ Historial de ConversaciÃ³n:\n",
      "================================================================================\n",
      "ğŸ‘¤ Usuario: Hola, estoy buscando una laptop para trabajar desde casa\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola! Â¡Claro que sÃ­! Para ayudarte mejor, Â¿me podrÃ­as decir un poco mÃ¡s sobre lo que necesitas? Por ejemplo:\n",
      "\n",
      "- Â¿QuÃ© tipo de trabajo realizas (oficina, diseÃ±o, programaciÃ³n, etc.)?\n",
      "- Â¿Tienes un presupuesto especÃ­fico?\n",
      "- Â¿Prefieres una laptop ligera y portÃ¡til o algo mÃ¡s potente?\n",
      "\n",
      "Â¡Estoy aquÃ­ para recomendarte lo mejor segÃºn tus necesidades! ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿CuÃ¡nto cuesta?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola nuevamente! La laptop HP Pavilion 15 cuesta $899. Es una opciÃ³n muy buena para trabajar desde casa, ya que cuenta con un procesador Intel i5, 8GB de RAM y 256GB de almacenamiento SSD, lo que la hace rÃ¡pida y eficiente para tareas de oficina y uso general. Â¿Te gustarÃ­a que te ayude a compararla con otras opciones? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿Tiene envÃ­o gratis?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola! SÃ­, tenemos envÃ­o gratis en todas las compras mayores a $100. Si tu compra es menor a ese monto, el costo del envÃ­o serÃ¡ calculado durante el proceso de pago. Â¿EstÃ¡s considerando comprar la laptop HP Pavilion 15 o alguna otra opciÃ³n? Â¡Estoy aquÃ­ para ayudarte! ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Claro que sÃ­! Tenemos el **Mouse Logitech MX Master 3** a $99. Es un mouse inalÃ¡mbrico ergonÃ³mico con 7 botones programables, ideal para trabajar de forma cÃ³moda y eficiente. Â¿Te gustarÃ­a que te lo describa mÃ¡s en detalle o que lo compare con otras opciones? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Perfecto! Si te interesa la **Laptop HP Pavilion 15** ($899) y el **Mouse Logitech MX Master 3** ($99), el total serÃ­a de **$998**. \n",
      "\n",
      "Como esta compra supera los $100, Â¡tendrÃ¡s **envÃ­o gratis**! Â¿Quieres que te ayude a realizar el pedido o quieres conocer mÃ¡s opciones antes de continuar? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Hola, estoy buscando una laptop para trabajar desde casa\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola! Â¡Claro que sÃ­! Para ayudarte mejor, Â¿me podrÃ­as decir un poco mÃ¡s sobre lo que necesitas? Por ejemplo:\n",
      "\n",
      "- Â¿QuÃ© tipo de trabajo realizas (oficina, diseÃ±o, programaciÃ³n, etc.)?\n",
      "- Â¿Tienes un presupuesto especÃ­fico?\n",
      "- Â¿Prefieres una laptop ligera y portÃ¡til o algo mÃ¡s potente?\n",
      "\n",
      "Â¡Estoy aquÃ­ para recomendarte lo mejor segÃºn tus necesidades! ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿CuÃ¡nto cuesta?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola nuevamente! La laptop HP Pavilion 15 cuesta $899. Es una opciÃ³n muy buena para trabajar desde casa, ya que cuenta con un procesador Intel i5, 8GB de RAM y 256GB de almacenamiento SSD, lo que la hace rÃ¡pida y eficiente para tareas de oficina y uso general. Â¿Te gustarÃ­a que te ayude a compararla con otras opciones? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Â¿Tiene envÃ­o gratis?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Hola! SÃ­, tenemos envÃ­o gratis en todas las compras mayores a $100. Si tu compra es menor a ese monto, el costo del envÃ­o serÃ¡ calculado durante el proceso de pago. Â¿EstÃ¡s considerando comprar la laptop HP Pavilion 15 o alguna otra opciÃ³n? Â¡Estoy aquÃ­ para ayudarte! ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Perfecto, tambiÃ©n necesito un mouse inalÃ¡mbrico. Â¿QuÃ© tienes?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Claro que sÃ­! Tenemos el **Mouse Logitech MX Master 3** a $99. Es un mouse inalÃ¡mbrico ergonÃ³mico con 7 botones programables, ideal para trabajar de forma cÃ³moda y eficiente. Â¿Te gustarÃ­a que te lo describa mÃ¡s en detalle o que lo compare con otras opciones? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ‘¤ Usuario: Me interesa el MX Master 3. Â¿CuÃ¡l serÃ­a el total con ambos productos?\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ¤– Bot: Â¡Perfecto! Si te interesa la **Laptop HP Pavilion 15** ($899) y el **Mouse Logitech MX Master 3** ($99), el total serÃ­a de **$998**. \n",
      "\n",
      "Como esta compra supera los $100, Â¡tendrÃ¡s **envÃ­o gratis**! Â¿Quieres que te ayude a realizar el pedido o quieres conocer mÃ¡s opciones antes de continuar? ğŸ˜Š\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de interacciones: 10\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š EstadÃ­sticas:\n",
      "   Total de mensajes en memoria: 20\n",
      "   Interacciones del usuario: 10\n"
     ]
    }
   ],
   "source": [
    "# Ver historial completo\n",
    "chatbot.ver_historial()\n",
    "\n",
    "# Ver estadÃ­sticas\n",
    "chatbot.estadisticas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Parte 11: ComparaciÃ³n Completa de Tipos de Memoria\n",
    "\n",
    "En LangChain existen **5 tipos principales de memoria**, cada uno diseÃ±ado para diferentes escenarios de uso. En esta secciÃ³n compararemos todos los tipos disponibles:\n",
    "\n",
    "1. **ConversationBufferMemory** - Almacena TODO el historial completo\n",
    "2. **ConversationBufferWindowMemory** - Solo las Ãºltimas K interacciones\n",
    "3. **ConversationSummaryMemory** - Resume la conversaciÃ³n progresivamente\n",
    "4. **ConversationSummaryBufferMemory** - HÃ­brido: mensajes recientes + resumen de antiguos\n",
    "5. **ConversationEntityMemory** - Rastrea entidades especÃ­ficas (personas, lugares, productos)\n",
    "\n",
    "Ejecuta la celda siguiente para ver ejemplos prÃ¡cticos de cada tipo y una tabla comparativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ğŸ”„ TIPOS DE MEMORIA EN LANGCHAIN\n",
    "# ==============================================================================\n",
    "# LangChain ofrece diferentes tipos de memoria, cada uno con caracterÃ­sticas Ãºnicas:\n",
    "# \n",
    "# 1. ConversationBufferMemory - Almacena TODO el historial\n",
    "# 2. ConversationBufferWindowMemory - Solo las Ãºltimas K interacciones\n",
    "# 3. ConversationSummaryMemory - Resume la conversaciÃ³n completa\n",
    "# 4. ConversationSummaryBufferMemory - HÃ­brido: mensajes recientes + resumen de antiguos\n",
    "# 5. ConversationEntityMemory - Rastrea entidades especÃ­ficas (personas, lugares, etc.)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"ğŸ§  COMPARACIÃ“N DE TIPOS DE MEMORIA EN LANGCHAIN\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1ï¸âƒ£  CONVERSATIONBUFFERMEMORY - Memoria Completa\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"1ï¸âƒ£  CONVERSATIONBUFFERMEMORY - Almacena TODO el historial\")\n",
    "print(\"=\" * 100)\n",
    "print(\"âœ… Ventajas: MÃ¡ximo contexto, recuerda todo\")\n",
    "print(\"âŒ Desventajas: Consume muchos tokens, puede ser costoso\")\n",
    "print(\"ğŸ¯ Uso ideal: Conversaciones cortas o cuando necesitas TODO el contexto\\n\")\n",
    "\n",
    "memory_buffer = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm_buffer = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "conversation_buffer = ConversationChain(\n",
    "    llm=llm_buffer,\n",
    "    memory=memory_buffer,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "chatbot_buffer = ChatbotEcommerce(conversation_buffer)\n",
    "\n",
    "# Test\n",
    "mensajes_buffer = [\n",
    "    \"Hola, me llamo MarÃ­a y busco una laptop\",\n",
    "    \"Â¿CuÃ¡l recomiendas?\",\n",
    "    \"Â¿Recuerdas mi nombre?\"\n",
    "]\n",
    "\n",
    "for msg in mensajes_buffer:\n",
    "    print(f\"ğŸ‘¤ Usuario: {msg}\")\n",
    "    resp = chatbot_buffer.chat(msg)\n",
    "    print(f\"ğŸ¤– Bot: {resp}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "print(\"ğŸ’¡ Resultado: Recuerda TODO, incluyendo el nombre 'MarÃ­a'\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2ï¸âƒ£  CONVERSATIONBUFFERWINDOWMEMORY - Ventana Deslizante\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"2ï¸âƒ£  CONVERSATIONBUFFERWINDOWMEMORY - Solo Ãºltimas K interacciones\")\n",
    "print(\"=\" * 100)\n",
    "print(\"âœ… Ventajas: Controla el uso de tokens, memoria eficiente\")\n",
    "print(\"âŒ Desventajas: Olvida conversaciones antiguas\")\n",
    "print(\"ğŸ¯ Uso ideal: Conversaciones largas donde solo importa el contexto reciente\\n\")\n",
    "\n",
    "memory_window = ConversationBufferWindowMemory(\n",
    "    k=2,  # Solo las Ãºltimas 2 interacciones\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm_window = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "conversation_window = ConversationChain(\n",
    "    llm=llm_window,\n",
    "    memory=memory_window,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "chatbot_window = ChatbotEcommerce(conversation_window)\n",
    "\n",
    "# Test con 4 mensajes (k=2 solo recordarÃ¡ los Ãºltimos 2)\n",
    "mensajes_window = [\n",
    "    \"Hola, me llamo Juan\",\n",
    "    \"Busco auriculares con cancelaciÃ³n de ruido\",\n",
    "    \"Â¿CuÃ¡l es el precio?\",\n",
    "    \"Â¿Recuerdas mi nombre?\"  # Esta pregunta probarÃ¡ la memoria limitada\n",
    "]\n",
    "\n",
    "for msg in mensajes_window:\n",
    "    print(f\"ğŸ‘¤ Usuario: {msg}\")\n",
    "    resp = chatbot_window.chat(msg)\n",
    "    print(f\"ğŸ¤– Bot: {resp}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "print(\"ğŸ’¡ Resultado: Con k=2, probablemente NO recuerda 'Juan' porque quedÃ³ fuera de la ventana\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3ï¸âƒ£  CONVERSATIONSUMMARYMEMORY - Resumen Progresivo\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"3ï¸âƒ£  CONVERSATIONSUMMARYMEMORY - Resume la conversaciÃ³n\")\n",
    "print(\"=\" * 100)\n",
    "print(\"âœ… Ventajas: Mantiene contexto con pocos tokens, ideal para conversaciones largas\")\n",
    "print(\"âŒ Desventajas: Pierde detalles especÃ­ficos, requiere LLM para resumir\")\n",
    "print(\"ğŸ¯ Uso ideal: Conversaciones muy largas donde necesitas contexto general\\n\")\n",
    "\n",
    "memory_summary = ConversationSummaryMemory(\n",
    "    llm=ChatOpenAI(\n",
    "        model=\"qwen-turbo\",\n",
    "        temperature=0.3,  # MÃ¡s bajo para resÃºmenes consistentes\n",
    "        max_tokens=300,\n",
    "        base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "    ),\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm_summary = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "conversation_summary = ConversationChain(\n",
    "    llm=llm_summary,\n",
    "    memory=memory_summary,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "chatbot_summary = ChatbotEcommerce(conversation_summary)\n",
    "\n",
    "# Test\n",
    "mensajes_summary = [\n",
    "    \"Hola, soy Pedro y necesito un monitor 4K\",\n",
    "    \"Mi presupuesto es de mÃ¡ximo $500\",\n",
    "    \"Â¿QuÃ© opciones tengo?\",\n",
    "    \"Â¿Recuerdas mi nombre y presupuesto?\"\n",
    "]\n",
    "\n",
    "for msg in mensajes_summary:\n",
    "    print(f\"ğŸ‘¤ Usuario: {msg}\")\n",
    "    resp = chatbot_summary.chat(msg)\n",
    "    print(f\"ğŸ¤– Bot: {resp}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "print(\"ğŸ’¡ Resultado: Resume la conversaciÃ³n, puede recordar informaciÃ³n clave como nombre y presupuesto\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4ï¸âƒ£  CONVERSATIONSUMMARYBUFFERMEMORY - HÃ­brido\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"4ï¸âƒ£  CONVERSATIONSUMMARYBUFFERMEMORY - Mensajes recientes + Resumen de antiguos\")\n",
    "print(\"=\" * 100)\n",
    "print(\"âœ… Ventajas: Balance perfecto entre detalle y eficiencia\")\n",
    "print(\"âŒ Desventajas: MÃ¡s complejo de configurar\")\n",
    "print(\"ğŸ¯ Uso ideal: Conversaciones largas donde necesitas detalles recientes + contexto histÃ³rico\\n\")\n",
    "\n",
    "memory_summary_buffer = ConversationSummaryBufferMemory(\n",
    "    llm=ChatOpenAI(\n",
    "        model=\"qwen-turbo\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=300,\n",
    "        base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "    ),\n",
    "    max_token_limit=200,  # Cuando excede este lÃ­mite, resume los mensajes antiguos\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm_summary_buffer = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "conversation_summary_buffer = ConversationChain(\n",
    "    llm=llm_summary_buffer,\n",
    "    memory=memory_summary_buffer,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "chatbot_summary_buffer = ChatbotEcommerce(conversation_summary_buffer)\n",
    "\n",
    "# Test\n",
    "mensajes_summary_buffer = [\n",
    "    \"Hola, me llamo Ana y trabajo en diseÃ±o grÃ¡fico\",\n",
    "    \"Necesito una laptop potente para renderizado\",\n",
    "    \"TambiÃ©n un monitor con buena precisiÃ³n de color\",\n",
    "    \"Â¿QuÃ© me recomiendas?\",\n",
    "    \"Â¿Recuerdas mi nombre y profesiÃ³n?\"\n",
    "]\n",
    "\n",
    "for msg in mensajes_summary_buffer:\n",
    "    print(f\"ğŸ‘¤ Usuario: {msg}\")\n",
    "    resp = chatbot_summary_buffer.chat(msg)\n",
    "    print(f\"ğŸ¤– Bot: {resp}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "print(\"ğŸ’¡ Resultado: Mantiene mensajes recientes completos y resume los antiguos\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5ï¸âƒ£  CONVERSATIONENTITYMEMORY - Seguimiento de Entidades\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"5ï¸âƒ£  CONVERSATIONENTITYMEMORY - Rastrea entidades especÃ­ficas\")\n",
    "print(\"=\" * 100)\n",
    "print(\"âœ… Ventajas: Excelente para recordar detalles sobre personas, lugares, productos\")\n",
    "print(\"âŒ Desventajas: Requiere LLM adicional para extraer entidades\")\n",
    "print(\"ğŸ¯ Uso ideal: Soporte al cliente, CRM, asistentes personalizados\\n\")\n",
    "\n",
    "memory_entity = ConversationEntityMemory(\n",
    "    llm=ChatOpenAI(\n",
    "        model=\"qwen-turbo\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=300,\n",
    "        base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "    ),\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "llm_entity = ChatOpenAI(\n",
    "    model=\"qwen-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "conversation_entity = ConversationChain(\n",
    "    llm=llm_entity,\n",
    "    memory=memory_entity,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "chatbot_entity = ChatbotEcommerce(conversation_entity)\n",
    "\n",
    "# Test\n",
    "mensajes_entity = [\n",
    "    \"Hola, soy Carlos de la empresa TechCorp\",\n",
    "    \"Necesito comprar 5 laptops HP Pavilion 15\",\n",
    "    \"TambiÃ©n 10 mouse Logitech\",\n",
    "    \"Â¿CuÃ¡l serÃ­a el total y hay descuento por volumen?\",\n",
    "    \"Â¿Recuerdas mi nombre, empresa y quÃ© productos quiero?\"\n",
    "]\n",
    "\n",
    "for msg in mensajes_entity:\n",
    "    print(f\"ğŸ‘¤ Usuario: {msg}\")\n",
    "    resp = chatbot_entity.chat(msg)\n",
    "    print(f\"ğŸ¤– Bot: {resp}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "print(\"ğŸ’¡ Resultado: Rastrea entidades como nombre (Carlos), empresa (TechCorp), productos, cantidades\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ğŸ“Š TABLA COMPARATIVA FINAL\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“Š TABLA COMPARATIVA DE TIPOS DE MEMORIA\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Tipo de Memoria              â”‚ Uso de Tokens  â”‚ RetenciÃ³n        â”‚ Mejor Caso de Uso         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ ConversationBufferMemory     â”‚ Alto           â”‚ 100%             â”‚ Chats cortos              â”‚\n",
    "â”‚ ConversationBufferWindow     â”‚ Medio          â”‚ Ãšltimas K msgs   â”‚ Chats largos, contexto    â”‚\n",
    "â”‚                              â”‚                â”‚                  â”‚ reciente importante       â”‚\n",
    "â”‚ ConversationSummaryMemory    â”‚ Bajo           â”‚ Resumen general  â”‚ Chats muy largos          â”‚\n",
    "â”‚ ConversationSummaryBuffer    â”‚ Medio-Bajo     â”‚ HÃ­brido          â”‚ Balance contexto/costo    â”‚\n",
    "â”‚ ConversationEntityMemory     â”‚ Medio          â”‚ Entidades clave  â”‚ CRM, soporte, ventas      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom typing import Dict, List, Any\nfrom datetime import datetime\nimport os\n\n# ==============================================================================\n# ğŸ“‹ EXTRACCIÃ“N DE DATOS ESTRUCTURADOS EN JSON\n# ==============================================================================\n\nprint(\"=\" * 100)\nprint(\"ğŸ“‹ CHATBOT CON RESPUESTAS ESTRUCTURADAS EN JSON\")\nprint(\"=\" * 100)\n\n# ==============================================================================\n# PASO 1: Crear un catÃ¡logo de productos estructurado\n# ==============================================================================\nCATALOGO_PRODUCTOS = {\n    \"PROD-001\": {\n        \"nombre\": \"Laptop HP Pavilion 15\",\n        \"precio\": 899,\n        \"categoria\": \"laptops\",\n        \"especificaciones\": \"Intel i5, 8GB RAM, 256GB SSD, Pantalla 15.6\\\"\"\n    },\n    \"PROD-002\": {\n        \"nombre\": \"Mouse Logitech MX Master 3\",\n        \"precio\": 99,\n        \"categoria\": \"accesorios\",\n        \"especificaciones\": \"InalÃ¡mbrico, ErgonÃ³mico, 7 botones programables\"\n    },\n    \"PROD-003\": {\n        \"nombre\": \"Teclado MecÃ¡nico Keychron K2\",\n        \"precio\": 79,\n        \"categoria\": \"accesorios\",\n        \"especificaciones\": \"Bluetooth, RGB, Switch Brown\"\n    },\n    \"PROD-004\": {\n        \"nombre\": \"Monitor Dell 27\\\" 4K\",\n        \"precio\": 449,\n        \"categoria\": \"monitores\",\n        \"especificaciones\": \"IPS, HDR, 60Hz, USB-C\"\n    },\n    \"PROD-005\": {\n        \"nombre\": \"Webcam Logitech C920\",\n        \"precio\": 79,\n        \"categoria\": \"accesorios\",\n        \"especificaciones\": \"Full HD 1080p, MicrÃ³fono integrado\"\n    },\n    \"PROD-006\": {\n        \"nombre\": \"Auriculares Sony WH-1000XM5\",\n        \"precio\": 399,\n        \"categoria\": \"audio\",\n        \"especificaciones\": \"CancelaciÃ³n de ruido, Bluetooth, 30h baterÃ­a\"\n    }\n}\n\n# Crear informaciÃ³n del catÃ¡logo para el prompt\ncatalogo_info = \"\\n\".join([\n    f\"{codigo}. {info['nombre']} - ${info['precio']} - {info['especificaciones']}\"\n    for codigo, info in CATALOGO_PRODUCTOS.items()\n])\n\n# ==============================================================================\n# PASO 2: Crear un prompt que solicite respuesta en JSON\n# ==============================================================================\njson_extraction_template = \"\"\"Eres un asistente de ventas para TechStore que extrae informaciÃ³n de conversaciones con clientes.\n\nTu tarea es DOBLE:\n1. Responder de manera amigable y profesional al cliente (en el campo \"respuesta_cliente\")\n2. Extraer informaciÃ³n estructurada de la conversaciÃ³n (en los demÃ¡s campos JSON)\n\nCatÃ¡logo de productos:\n{catalogo_info}\n\nIMPORTANTE: Debes responder ÃšNICAMENTE con un objeto JSON vÃ¡lido con la siguiente estructura:\n{{\n    \"respuesta_cliente\": \"Tu respuesta amigable al cliente aquÃ­\",\n    \"cliente\": {{\n        \"nombre\": \"nombre del cliente si lo mencionÃ³, o null\",\n        \"empresa\": \"empresa si la mencionÃ³, o null\"\n    }},\n    \"productos_mencionados\": [\n        {{\n            \"codigo\": \"PROD-XXX\",\n            \"nombre\": \"Nombre del producto\",\n            \"cantidad\": 1,\n            \"precio_unitario\": 0\n        }}\n    ],\n    \"intencion\": \"consulta|cotizacion|compra\",\n    \"requiere_envio\": true|false,\n    \"total_estimado\": 0,\n    \"notas_adicionales\": \"cualquier informaciÃ³n relevante\"\n}}\n\nHistorial de conversaciÃ³n:\n{chat_history}\n\nCliente: {input}\n\nJSON de respuesta:\"\"\"\n\n# Crear el prompt con partial_variables para incluir el catÃ¡logo de forma fija\n# Esto permite que ConversationChain solo vea las variables chat_history e input\njson_prompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"input\"],\n    template=json_extraction_template,\n    partial_variables={\"catalogo_info\": catalogo_info}\n)\n\nprint(\"âœ… Prompt JSON creado con catÃ¡logo incluido\")\n\n# ==============================================================================\n# PASO 3: Crear LLM configurado para JSON\n# ==============================================================================\nllm_json = ChatOpenAI(\n    model=\"qwen-turbo\",\n    temperature=0.3,  # MÃ¡s bajo para respuestas mÃ¡s consistentes\n    max_tokens=800,   # MÃ¡s tokens para respuestas JSON detalladas\n    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n)\n\n# Crear memoria para el contexto\nmemory_json = ConversationBufferMemory(\n    return_messages=True,\n    memory_key=\"chat_history\"\n)\n\n# Crear la cadena de conversaciÃ³n\nconversation_json = ConversationChain(\n    llm=llm_json,\n    memory=memory_json,\n    prompt=json_prompt,\n    verbose=False\n)\n\nprint(\"âœ… ConversationChain para JSON creada correctamente\")\n\n# ==============================================================================\n# PASO 4: FunciÃ³n para procesar y parsear respuestas JSON\n# ==============================================================================\ndef extraer_json_de_respuesta(respuesta: str) -> Dict[str, Any]:\n    \"\"\"\n    Extrae y parsea JSON de la respuesta del LLM\n    \"\"\"\n    try:\n        # Intentar parsear directamente\n        return json.loads(respuesta)\n    except json.JSONDecodeError:\n        # Si falla, intentar extraer JSON entre llaves\n        import re\n        json_match = re.search(r'\\{.*\\}', respuesta, re.DOTALL)\n        if json_match:\n            try:\n                return json.loads(json_match.group())\n            except:\n                pass\n        \n        # Si todo falla, retornar estructura vacÃ­a\n        return {\n            \"respuesta_cliente\": respuesta,\n            \"error\": \"No se pudo parsear JSON\"\n        }\n\ndef procesar_conversacion_json(mensaje: str) -> tuple:\n    \"\"\"\n    Procesa un mensaje y retorna la respuesta + datos estructurados\n    \"\"\"\n    # Obtener respuesta del LLM\n    respuesta_raw = conversation_json.predict(input=mensaje)\n    \n    # Parsear JSON\n    datos_estructurados = extraer_json_de_respuesta(respuesta_raw)\n    \n    # Obtener respuesta para el cliente\n    respuesta_cliente = datos_estructurados.get(\"respuesta_cliente\", respuesta_raw)\n    \n    return respuesta_cliente, datos_estructurados\n\n# ==============================================================================\n# PASO 5: Probar con conversaciones de ejemplo\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"ğŸ§ª EJEMPLOS DE EXTRACCIÃ“N DE DATOS ESTRUCTURADOS\")\nprint(\"=\" * 100)\n\nconversaciones_ejemplo = [\n    \"Hola, soy MarÃ­a GonzÃ¡lez de la empresa TechCorp y necesito cotizar 3 laptops HP Pavilion\",\n    \"TambiÃ©n necesitamos 5 mouse Logitech para la oficina\",\n    \"Â¿CuÃ¡l serÃ­a el total con envÃ­o incluido?\",\n    \"Perfecto, quiero proceder con la compra\"\n]\n\n# Procesar cada mensaje\ndatos_extraidos_totales = []\n\nfor i, mensaje in enumerate(conversaciones_ejemplo, 1):\n    print(f\"\\n{'â”€' * 100}\")\n    print(f\"ğŸ’¬ Mensaje {i}: {mensaje}\")\n    print(f\"{'â”€' * 100}\")\n    \n    # Procesar mensaje\n    respuesta, datos = procesar_conversacion_json(mensaje)\n    \n    # Mostrar respuesta al cliente\n    print(f\"\\nğŸ¤– Respuesta al Cliente:\")\n    print(f\"   {respuesta}\")\n    \n    # Mostrar datos estructurados extraÃ­dos\n    print(f\"\\nğŸ“Š Datos Estructurados ExtraÃ­dos:\")\n    print(json.dumps(datos, indent=4, ensure_ascii=False))\n    \n    datos_extraidos_totales.append(datos)\n\n# ==============================================================================\n# PASO 6: Resumen de informaciÃ³n extraÃ­da\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"ğŸ“ˆ RESUMEN DE INFORMACIÃ“N EXTRAÃDA DE TODA LA CONVERSACIÃ“N\")\nprint(\"=\" * 100)\n\n# Extraer informaciÃ³n consolidada\ncliente_nombre = None\ncliente_empresa = None\nproductos_totales = []\nintencion_final = None\n\nfor datos in datos_extraidos_totales:\n    # Extraer informaciÃ³n del cliente\n    if datos.get(\"cliente\"):\n        if datos[\"cliente\"].get(\"nombre\"):\n            cliente_nombre = datos[\"cliente\"][\"nombre\"]\n        if datos[\"cliente\"].get(\"empresa\"):\n            cliente_empresa = datos[\"cliente\"][\"empresa\"]\n    \n    # Acumular productos\n    if datos.get(\"productos_mencionados\"):\n        productos_totales.extend(datos[\"productos_mencionados\"])\n    \n    # Ãšltima intenciÃ³n\n    if datos.get(\"intencion\"):\n        intencion_final = datos[\"intencion\"]\n\n# Calcular total\ntotal_pedido = sum(\n    p.get(\"precio_unitario\", 0) * p.get(\"cantidad\", 1) \n    for p in productos_totales\n)\n\n# Mostrar resumen\nresumen = {\n    \"cliente\": {\n        \"nombre\": cliente_nombre,\n        \"empresa\": cliente_empresa\n    },\n    \"productos_solicitados\": productos_totales,\n    \"cantidad_items\": len(productos_totales),\n    \"total_estimado\": total_pedido,\n    \"intencion_final\": intencion_final,\n    \"requiere_seguimiento\": intencion_final == \"compra\"\n}\n\nprint(json.dumps(resumen, indent=4, ensure_ascii=False))\n\n# ==============================================================================\n# PASO 7: Funciones para guardar en JSON (IMPLEMENTACIÃ“N REAL)\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"ğŸ”— EJEMPLO: INTEGRACIÃ“N CON SISTEMA BACKEND (GUARDADO EN JSON)\")\nprint(\"=\" * 100)\n\n# Nombre del archivo JSON donde se guardarÃ¡n los pedidos\nARCHIVO_PEDIDOS = \"pedidos_techstore.json\"\n\ndef cargar_pedidos_existentes() -> List[Dict[str, Any]]:\n    \"\"\"\n    Carga los pedidos existentes desde el archivo JSON\n    \"\"\"\n    if os.path.exists(ARCHIVO_PEDIDOS):\n        try:\n            with open(ARCHIVO_PEDIDOS, 'r', encoding='utf-8') as f:\n                return json.load(f)\n        except:\n            return []\n    return []\n\ndef generar_id_pedido() -> str:\n    \"\"\"\n    Genera un ID Ãºnico para el pedido basado en timestamp\n    \"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n    return f\"PED-{timestamp}\"\n\ndef guardar_pedido_en_bd(datos_pedido: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Guarda el pedido en un archivo JSON real\n    \n    Args:\n        datos_pedido: Diccionario con informaciÃ³n del pedido\n        \n    Returns:\n        Diccionario con pedido_id y status\n    \"\"\"\n    print(\"\\nğŸ“ Guardando pedido en archivo JSON...\")\n    \n    # Cargar pedidos existentes\n    pedidos = cargar_pedidos_existentes()\n    \n    # Generar ID Ãºnico\n    pedido_id = generar_id_pedido()\n    \n    # Crear estructura completa del pedido\n    pedido_completo = {\n        \"pedido_id\": pedido_id,\n        \"fecha_creacion\": datetime.now().isoformat(),\n        \"status\": \"pending\",\n        \"cliente\": datos_pedido.get(\"cliente\", {}),\n        \"productos\": datos_pedido.get(\"productos_solicitados\", []),\n        \"cantidad_items\": datos_pedido.get(\"cantidad_items\", 0),\n        \"total_estimado\": datos_pedido.get(\"total_estimado\", 0),\n        \"intencion\": datos_pedido.get(\"intencion_final\", \"\"),\n        \"requiere_seguimiento\": datos_pedido.get(\"requiere_seguimiento\", False)\n    }\n    \n    # Agregar nuevo pedido a la lista\n    pedidos.append(pedido_completo)\n    \n    # Guardar en archivo JSON\n    with open(ARCHIVO_PEDIDOS, 'w', encoding='utf-8') as f:\n        json.dump(pedidos, f, indent=4, ensure_ascii=False)\n    \n    # Mostrar informaciÃ³n\n    print(f\"   âœ… Pedido guardado correctamente\")\n    print(f\"   ğŸ“„ Archivo: {ARCHIVO_PEDIDOS}\")\n    print(f\"   ğŸ†” ID Pedido: {pedido_id}\")\n    print(f\"   ğŸ‘¤ Cliente: {datos_pedido['cliente']['nombre']}\")\n    print(f\"   ğŸ¢ Empresa: {datos_pedido['cliente']['empresa']}\")\n    print(f\"   ğŸ“¦ Total items: {datos_pedido['cantidad_items']}\")\n    print(f\"   ğŸ’° Total: ${datos_pedido['total_estimado']}\")\n    print(f\"   ğŸ“Š Estado: pending\")\n    \n    return {\"pedido_id\": pedido_id, \"status\": \"pending\"}\n\ndef enviar_notificacion_ventas(datos_pedido: Dict[str, Any]):\n    \"\"\"\n    Simula enviar notificaciÃ³n al equipo de ventas\n    TambiÃ©n guarda un log en archivo\n    \"\"\"\n    print(\"\\nğŸ“§ Enviando notificaciÃ³n al equipo de ventas...\")\n    \n    notificacion = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"tipo\": \"nueva_oportunidad\",\n        \"asunto\": f\"Nueva oportunidad de venta - {datos_pedido['cliente']['empresa']}\",\n        \"cliente\": datos_pedido['cliente']['nombre'],\n        \"empresa\": datos_pedido['cliente']['empresa'],\n        \"monto_estimado\": datos_pedido['total_estimado'],\n        \"productos\": datos_pedido['productos_solicitados']\n    }\n    \n    # Guardar notificaciÃ³n en archivo de log\n    archivo_log = \"notificaciones_ventas.json\"\n    \n    # Cargar notificaciones existentes\n    notificaciones = []\n    if os.path.exists(archivo_log):\n        try:\n            with open(archivo_log, 'r', encoding='utf-8') as f:\n                notificaciones = json.load(f)\n        except:\n            notificaciones = []\n    \n    # Agregar nueva notificaciÃ³n\n    notificaciones.append(notificacion)\n    \n    # Guardar en archivo\n    with open(archivo_log, 'w', encoding='utf-8') as f:\n        json.dump(notificaciones, f, indent=4, ensure_ascii=False)\n    \n    print(f\"   âœ… NotificaciÃ³n enviada y guardada\")\n    print(f\"   ï¿½ï¿½ Archivo: {archivo_log}\")\n    print(f\"   ğŸ“¬ Asunto: {notificacion['asunto']}\")\n    print(f\"   ğŸ’µ Monto estimado: ${datos_pedido['total_estimado']}\")\n\ndef mostrar_estadisticas_pedidos():\n    \"\"\"\n    Muestra estadÃ­sticas de los pedidos guardados\n    \"\"\"\n    if not os.path.exists(ARCHIVO_PEDIDOS):\n        print(\"\\nğŸ“Š No hay pedidos guardados aÃºn\")\n        return\n    \n    pedidos = cargar_pedidos_existentes()\n    \n    if not pedidos:\n        print(\"\\nğŸ“Š No hay pedidos guardados aÃºn\")\n        return\n    \n    print(\"\\n\" + \"=\" * 100)\n    print(\"ğŸ“Š ESTADÃSTICAS DE PEDIDOS GUARDADOS\")\n    print(\"=\" * 100)\n    \n    total_pedidos = len(pedidos)\n    total_ingresos = sum(p.get(\"total_estimado\", 0) for p in pedidos)\n    total_items = sum(p.get(\"cantidad_items\", 0) for p in pedidos)\n    \n    print(f\"\\nğŸ“ˆ Resumen General:\")\n    print(f\"   Total de pedidos: {total_pedidos}\")\n    print(f\"   Total items vendidos: {total_items}\")\n    print(f\"   Ingresos totales: ${total_ingresos:,.2f}\")\n    print(f\"   Promedio por pedido: ${total_ingresos/total_pedidos:,.2f}\")\n    \n    print(f\"\\nğŸ“‹ Ãšltimos 3 pedidos:\")\n    for pedido in pedidos[-3:]:\n        print(f\"\\n   ğŸ†” {pedido['pedido_id']}\")\n        print(f\"      Cliente: {pedido['cliente'].get('nombre', 'N/A')}\")\n        print(f\"      Empresa: {pedido['cliente'].get('empresa', 'N/A')}\")\n        print(f\"      Total: ${pedido.get('total_estimado', 0)}\")\n        print(f\"      Fecha: {pedido.get('fecha_creacion', 'N/A')[:19]}\")\n\n# ==============================================================================\n# PASO 8: Guardar el pedido y enviar notificaciÃ³n\n# ==============================================================================\n\n# Simular integraciÃ³n\nif resumen[\"intencion_final\"] == \"compra\":\n    resultado_bd = guardar_pedido_en_bd(resumen)\n    enviar_notificacion_ventas(resumen)\n    print(f\"\\nğŸ‰ Pedido procesado exitosamente: {resultado_bd['pedido_id']}\")\n    \n    # Mostrar estadÃ­sticas\n    mostrar_estadisticas_pedidos()\nelse:\n    print(\"\\nğŸ’¡ La intenciÃ³n no es 'compra', no se guardarÃ¡ el pedido\")\n    print(f\"   IntenciÃ³n actual: {resumen['intencion_final']}\")\n\n# ==============================================================================\n# ğŸ’¡ VENTAJAS DE USAR JSON ESTRUCTURADO\n# ==============================================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"ğŸ’¡ VENTAJAS DE USAR RESPUESTAS JSON ESTRUCTURADAS\")\nprint(\"=\" * 100)\nprint(\"\"\"\nâœ… IntegraciÃ³n fÃ¡cil con sistemas backend (CRM, ERP, bases de datos)\nâœ… AnÃ¡lisis y reportes automatizados\nâœ… ValidaciÃ³n de datos mÃ¡s robusta\nâœ… Procesamiento programÃ¡tico de entidades\nâœ… Seguimiento estructurado de conversaciones\nâœ… AutomatizaciÃ³n de workflows (pedidos, cotizaciones, seguimientos)\nâœ… Analytics y mÃ©tricas de ventas en tiempo real\nâœ… Facilita el testing y debugging\n\nğŸ¯ Casos de uso:\n- Sistemas de pedidos automatizados\n- CRM integrado con chatbot\n- Analytics de conversaciones\n- AutomatizaciÃ³n de cotizaciones\n- GestiÃ³n de inventario en tiempo real\n- Reportes de ventas y tendencias\n\nğŸ“ Archivos generados en este ejemplo:\n- pedidos_techstore.json: Base de datos de pedidos\n- notificaciones_ventas.json: Log de notificaciones enviadas\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Parte 11.5: ExtracciÃ³n de Datos Estructurados en JSON\n",
    "\n",
    "En aplicaciones reales, a menudo necesitamos extraer informaciÃ³n especÃ­fica de la conversaciÃ³n en un formato estructurado (JSON) para procesarla programÃ¡ticamente. Por ejemplo:\n",
    "\n",
    "- **CÃ³digos de productos** mencionados\n",
    "- **Nombres de clientes**\n",
    "- **Cantidades** solicitadas\n",
    "- **Precios** y totales\n",
    "- **IntenciÃ³n de compra** (consulta, cotizaciÃ³n, compra)\n",
    "- **Entidades extraÃ­das** (fechas, ubicaciones, etc.)\n",
    "\n",
    "Esta secciÃ³n muestra cÃ³mo configurar el LLM para que devuelva respuestas en formato JSON que pueden ser parseadas y utilizadas por otros sistemas (bases de datos, CRM, sistemas de pedidos, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ­ Parte 12: Chatbot Interactivo en Consola\n",
    "\n",
    "Crea un loop interactivo para chatear en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciar_chat_interactivo():\n",
    "    \"\"\"\n",
    "    Inicia un chat interactivo en la consola\n",
    "    \"\"\"\n",
    "    # Crear nuevo LLM para la sesiÃ³n interactiva\n",
    "    llm_interactivo = ChatOpenAI(\n",
    "        model=\"qwen-turbo\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "        base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "    \n",
    "    # Crear nueva memoria para sesiÃ³n interactiva\n",
    "    memory_interactivo = ConversationBufferMemory(\n",
    "        return_messages=True,\n",
    "        memory_key=\"chat_history\"\n",
    "    )\n",
    "    \n",
    "    conversation_interactivo = ConversationChain(\n",
    "        llm=llm_interactivo,\n",
    "        memory=memory_interactivo,\n",
    "        prompt=prompt,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    chatbot_interactivo = ChatbotEcommerce(conversation_interactivo)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¤– CHATBOT INTERACTIVO - TECHSTORE (Powered by Alibaba Qwen)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Â¡Bienvenido a TechStore! Soy tu asistente virtual.\")\n",
    "    print(\"Escribe 'salir' para terminar la conversaciÃ³n.\")\n",
    "    print(\"Escribe 'historial' para ver la conversaciÃ³n completa.\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            mensaje = input(\"ğŸ‘¤ TÃº: \").strip()\n",
    "            \n",
    "            if not mensaje:\n",
    "                continue\n",
    "            \n",
    "            if mensaje.lower() in ['salir', 'exit', 'quit']:\n",
    "                print(\"\\nğŸ¤– Bot: Â¡Gracias por visitar TechStore! Que tengas un excelente dÃ­a.\")\n",
    "                break\n",
    "            \n",
    "            if mensaje.lower() == 'historial':\n",
    "                chatbot_interactivo.ver_historial()\n",
    "                continue\n",
    "            \n",
    "            # Generar respuesta\n",
    "            respuesta = chatbot_interactivo.chat(mensaje)\n",
    "            print(f\"\\nğŸ¤– Bot: {respuesta}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nğŸ¤– Bot: Â¡Hasta pronto!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error: {e}\")\n",
    "            print(\"Por favor, intenta de nuevo.\\n\")\n",
    "    \n",
    "    # Mostrar estadÃ­sticas finales\n",
    "    chatbot_interactivo.estadisticas()\n",
    "\n",
    "# Para iniciar el chat interactivo, ejecuta:\n",
    "# iniciar_chat_interactivo()\n",
    "\n",
    "print(\"âœ… FunciÃ³n de chat interactivo lista (usando Alibaba DashScope)\")\n",
    "print(\"\\nğŸ’¡ Para iniciar el chat interactivo, ejecuta: iniciar_chat_interactivo()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Parte 13: Ejercicios Propuestos\n",
    "\n",
    "### Ejercicio 1: Expandir el CatÃ¡logo\n",
    "Agrega mÃ¡s productos al catÃ¡logo en el prompt template.\n",
    "\n",
    "### Ejercicio 2: Sistema de Descuentos\n",
    "Implementa un sistema que aplique descuentos automÃ¡ticos basados en:\n",
    "- Monto total de compra\n",
    "- Cantidad de productos\n",
    "- Productos en combo\n",
    "\n",
    "### Ejercicio 3: Filtrado Inteligente\n",
    "Crea un sistema que filtre productos por:\n",
    "- Rango de precios\n",
    "- CategorÃ­a\n",
    "- CaracterÃ­sticas especÃ­ficas\n",
    "\n",
    "### Ejercicio 4: IntegraciÃ³n con Base de Datos\n",
    "Conecta el chatbot a una base de datos real (SQLite) para obtener informaciÃ³n de productos dinÃ¡micamente.\n",
    "\n",
    "### Ejercicio 5: Sentiment Analysis\n",
    "Agrega anÃ¡lisis de sentimiento para detectar clientes insatisfechos y escalar a soporte humano.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ†“ ALTERNATIVA: Usando Modelos Locales (Sin API Key)\n",
    "\n",
    "Si no tienes API key de OpenAI, puedes usar modelos locales de HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa con HuggingFace (sin costo)\n",
    "# !pip install langchain-huggingface -q\n",
    "\n",
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# # Cargar modelo local\n",
    "# model_id = \"google/flan-t5-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# # Crear pipeline\n",
    "# pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "\n",
    "# # Crear LLM de LangChain\n",
    "# llm_local = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# # Usar igual que antes\n",
    "# conversation_local = ConversationChain(\n",
    "#     llm=llm_local,\n",
    "#     memory=ConversationBufferMemory(),\n",
    "#     prompt=prompt\n",
    "# )\n",
    "\n",
    "print(\"ğŸ’¡ CÃ³digo de alternativa con HuggingFace disponible (comentado)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Conclusiones\n",
    "\n",
    "En este taller has aprendido a:\n",
    "\n",
    "âœ… Configurar LangChain con OpenAI GPT  \n",
    "âœ… Implementar gestiÃ³n de memoria conversacional  \n",
    "âœ… DiseÃ±ar prompts efectivos para chatbots especializados  \n",
    "âœ… Crear cadenas de procesamiento (ConversationChain)  \n",
    "âœ… Construir un chatbot funcional para e-commerce  \n",
    "âœ… Comparar diferentes estrategias de memoria\n",
    "\n",
    "### ğŸš€ PrÃ³ximos Pasos\n",
    "\n",
    "- Integrar con bases de datos reales\n",
    "- Implementar RAG para consultar documentos\n",
    "- Agregar herramientas externas (APIs, calculadoras)\n",
    "- Desplegar en producciÃ³n con Telegram/WhatsApp\n",
    "- Implementar agentes autÃ³nomos\n",
    "\n",
    "### ğŸ“š Recursos Adicionales\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [OpenAI API Reference](https://platform.openai.com/docs/)\n",
    "- [LangChain Cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Felicitaciones!** ğŸ‰ Has completado el Taller de la SesiÃ³n 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}